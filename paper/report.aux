\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nty/global//global/global}
\abx@aux@cite{0}{ansari2025chronos2}
\abx@aux@segm{0}{0}{ansari2025chronos2}
\abx@aux@cite{0}{vaswani2017attention}
\abx@aux@segm{0}{0}{vaswani2017attention}
\abx@aux@cite{0}{beltagy2020longformer}
\abx@aux@segm{0}{0}{beltagy2020longformer}
\abx@aux@cite{0}{child2019sparse}
\abx@aux@segm{0}{0}{child2019sparse}
\abx@aux@cite{0}{leviathan2025promptrepetitionimprovesnonreasoning}
\abx@aux@segm{0}{0}{leviathan2025promptrepetitionimprovesnonreasoning}
\abx@aux@cite{0}{ansari2025chronos2}
\abx@aux@segm{0}{0}{ansari2025chronos2}
\abx@aux@cite{0}{shchur2025fev}
\abx@aux@segm{0}{0}{shchur2025fev}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Problem Statement}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Sparse Time Attention}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Augmented Inference}{1}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Soft Group Masking}{1}{subsection.2.3}\protected@file@percent }
\abx@aux@cite{0}{zaheer2020bigbird}
\abx@aux@segm{0}{0}{zaheer2020bigbird}
\abx@aux@cite{0}{ansari2024chronos}
\abx@aux@segm{0}{0}{ansari2024chronos}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Semantic Cross-Learning}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Proposed Extensions}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}\textbf  {First extension: Sparse Time Attention}}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sparse time attention: windowed context (radius $r$) and global future attention.}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sparseAttention}{{1}{2}{Sparse time attention: windowed context (radius $r$) and global future attention}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Attention mass retained vs radius (context queries only)}}{2}{figure.caption.3}\protected@file@percent }
\newlabel{fig:sparsevsFullAttention}{{2}{2}{Attention mass retained vs radius (context queries only)}{figure.caption.3}{}}
\abx@aux@cite{0}{nie2022patchtst}
\abx@aux@segm{0}{0}{nie2022patchtst}
\abx@aux@cite{0}{dao2023flashattention2}
\abx@aux@segm{0}{0}{dao2023flashattention2}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Sparse time attention vs.\ full attention (all contexts pooled). $\Delta \text  {MASE}$ (negative is better). We report medians to reduce sensitivity to outlier tasks. Speedup values $<1$ indicate sparse is slower).}}{3}{table.caption.5}\protected@file@percent }
\newlabel{tab:sparse_radius_summary_minimal}{{I}{3}{Sparse time attention vs.\ full attention (all contexts pooled). $\Delta \text {MASE}$ (negative is better). We report medians to reduce sensitivity to outlier tasks. Speedup values $<1$ indicate sparse is slower)}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}\textbf  {Second extension: Augmented inference}}{3}{subsection.3.2}\protected@file@percent }
\abx@aux@cite{0}{ansari2025chronos2}
\abx@aux@segm{0}{0}{ansari2025chronos2}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Win rate, mean MASE, mean WQL and mean inference time for variants of the augmented inference extension. Evaluated on Chronos-Zeroshot benchmark}}{4}{table.caption.9}\protected@file@percent }
\newlabel{tab:aug}{{II}{4}{Win rate, mean MASE, mean WQL and mean inference time for variants of the augmented inference extension. Evaluated on Chronos-Zeroshot benchmark}{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}\textbf  {Third extension: Soft Group Masking Extension}}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0a}Motivation and Hypothesis}{4}{paragraph.3.3.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0b}Technical Approach}{4}{paragraph.3.3.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0c}Implementation Details}{4}{paragraph.3.3.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-C}0d}Results}{4}{paragraph.3.3.0.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Baseline (hard masking) vs. soft masking performance on Chronos Benchmark II. Lower is better for both metrics.}}{4}{table.caption.11}\protected@file@percent }
\newlabel{tab:soft-masking-results}{{III}{4}{Baseline (hard masking) vs. soft masking performance on Chronos Benchmark II. Lower is better for both metrics}{table.caption.11}{}}
\abx@aux@cite{0}{ansari2025chronos2}
\abx@aux@segm{0}{0}{ansari2025chronos2}
\abx@aux@cite{0}{shchur2025fev}
\abx@aux@segm{0}{0}{shchur2025fev}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}\textbf  {Fourth extension: Context Construction and Batched Inference}}{5}{subsection.3.4}\protected@file@percent }
\newlabel{sec:chronos2-extension}{{\mbox  {III-D}}{5}{\textbf {Fourth extension: Context Construction and Batched Inference}}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Chronos-2 inference pipeline with the proposed extension layer. The Chronos-2 forward pass is unchanged; the extension operates strictly \emph  {before} inference by constructing grouped contexts and assembling batches.}}{5}{figure.caption.12}\protected@file@percent }
\newlabel{fig:chronos2-extension}{{3}{5}{Chronos-2 inference pipeline with the proposed extension layer. The Chronos-2 forward pass is unchanged; the extension operates strictly \emph {before} inference by constructing grouped contexts and assembling batches}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-D}1}\textbf  {Experiments and evaluations}}{5}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Evaluation configuration and semantic extension defaults.}}{5}{table.caption.13}\protected@file@percent }
\newlabel{tab:chronos2-ext-setup}{{IV}{5}{Evaluation configuration and semantic extension defaults}{table.caption.13}{}}
\newlabel{sec:univar-results}{{\mbox  {III-D}1}{5}{\textbf {Experiments and evaluations}}{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Mean/median (lower is better). $\Delta (\%)$: mean percent gain (Semantic vs Random); WR$_{S<R}$: fraction where Semantic beats Random. $p_t$: paired $t$-test (two-sided); $p_W$: Wilcoxon (one-sided, $H_1$: Sem$<$Rand). ``Exploded'' MASE tasks (MASE$>10$ in any mode) are removed, yielding $n{=}80$.}}{5}{table.caption.14}\protected@file@percent }
\newlabel{tab:fev_one_table}{{V}{5}{Mean/median (lower is better). $\Delta (\%)$: mean percent gain (Semantic vs Random); WR$_{S<R}$: fraction where Semantic beats Random. $p_t$: paired $t$-test (two-sided); $p_W$: Wilcoxon (one-sided, $H_1$: Sem$<$Rand). ``Exploded'' MASE tasks (MASE$>10$ in any mode) are removed, yielding $n{=}80$}{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-D}2}\textbf  {Interpretation}}{5}{subsubsection.3.4.2}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{nobblfile}
\abx@aux@read@bblrerun
\gdef \@abspage@last{6}
