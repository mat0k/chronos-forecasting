{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chronos-2 Soft Group Masking Test\n",
    "\n",
    "This notebook tests the soft group masking extension for Chronos-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Install modified Chronos from GitHub and dependencies\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install from GitHub repository with soft masking extension\n",
    "    if not os.path.exists('/content/chronos-forecasting'):\n",
    "        !git clone https://github.com/mat0k/chronos-forecasting.git /content/chronos-forecasting\n",
    "        !cd /content/chronos-forecasting && git checkout soft_attention_2\n",
    "    !pip install -e /content/chronos-forecasting\n",
    "    print(\"✓ Installed Chronos from GitHub (soft_attention_2 branch)\")\n",
    "else:\n",
    "    print(\"Not in Colab - assuming local modified version is available\")\n",
    "\n",
    "# Install required dependencies\n",
    "!pip install -q pandas scipy matplotlib tqdm\n",
    "\n",
    "print(\"✓ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and define helper functions\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chronos import BaseChronosPipeline\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Helper functions for metric computation\n",
    "def compute_mae(y_true, y_pred):\n",
    "    \"\"\"Compute Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    \"\"\"Compute Root Mean Squared Error\"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def compute_mase(y_true, y_pred):\n",
    "    \"\"\"Compute Mean Absolute Scaled Error\"\"\"\n",
    "    n = len(y_true)\n",
    "    d = np.mean(np.abs(np.diff(y_true)))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae / d if d > 0 else 0.0\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Chronos-2 model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Chronos-2 model (uses the modified chronos2 code)\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-2\",\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded Chronos-2 model on {device}\")\n",
    "print(f\"Pipeline type: {type(pipeline).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Walmart Weekly dataset\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Walmart Weekly Sales Dataset Setup\")\n",
    "print(\"=\"*60)\n",
    "print(\"Download 'train.csv' from:\")\n",
    "print(\"https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting/data\")\n",
    "print(\"Then upload it using the button below\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Manual upload\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "csv_file = list(uploaded.keys())[0]\n",
    "print(f\"\\n✓ Uploaded: {csv_file}\")\n",
    "\n",
    "# Load Walmart data\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Pivot to get each Store-Dept combination as a time series\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df_pivot = df.pivot_table(index='Date', columns=['Store', 'Dept'], values='Weekly_Sales', aggfunc='sum')\n",
    "\n",
    "print(f\"✓ Loaded Walmart dataset\")\n",
    "print(f\"Shape: {df_pivot.shape} ({df_pivot.shape[1]} series × {df_pivot.shape[0]} weeks)\")\n",
    "\n",
    "# Create sliding window samples\n",
    "context_len = 52    # 1 year context\n",
    "horizon_len = 8     # 8 weeks forecast (2 months)\n",
    "samples = []\n",
    "\n",
    "# Use first 500 series for testing (2,936 total would take very long)\n",
    "n_series_to_use = 500\n",
    "\n",
    "print(f\"\\nCreating samples from first {n_series_to_use} series...\")\n",
    "for series_idx in range(min(n_series_to_use, df_pivot.shape[1])):\n",
    "    ts = df_pivot.iloc[:, series_idx].fillna(0).values.astype(np.float32)\n",
    "    \n",
    "    # Create sliding windows\n",
    "    for i in range(len(ts) - context_len - horizon_len + 1):\n",
    "        context = ts[i:i+context_len]\n",
    "        target = ts[i+context_len:i+context_len+horizon_len]\n",
    "        samples.append({\n",
    "            'context': context,\n",
    "            'target': target,\n",
    "            'series_id': series_idx\n",
    "        })\n",
    "\n",
    "print(f\"✓ Created {len(samples)} samples from {n_series_to_use} series\")\n",
    "print(f\"Context: {context_len} weeks, Forecast: {horizon_len} weeks\")\n",
    "\n",
    "# Store in format compatible with other cells\n",
    "all_datasets = {'walmart': samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prepare data for prediction\n",
    "samples = all_datasets['walmart']\n",
    "\n",
    "# Extract context and future values\n",
    "context = []\n",
    "future_values = []\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "for sample in tqdm(samples, desc=\"Extracting data\"):\n",
    "    context.append(torch.tensor(sample['context'], dtype=torch.float32))\n",
    "    future_values.append(torch.tensor(sample['target'], dtype=torch.float32))\n",
    "\n",
    "prediction_length = 8\n",
    "print(f\"✓ Prepared {len(context)} series for prediction\")\n",
    "print(f\"Prediction length: {prediction_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run baseline prediction (original hard masking) + compute metrics\n",
    "print(\"Running baseline prediction (hard group masking)...\")\n",
    "\n",
    "# Process in batches with progress bar\n",
    "batch_size = 256\n",
    "n_samples = len(context)\n",
    "n_batches = (n_samples + batch_size - 1) // batch_size\n",
    "\n",
    "baseline_preds = []\n",
    "baseline_mae_per_series = []\n",
    "baseline_rmse_per_series = []\n",
    "baseline_mase_per_series = []\n",
    "\n",
    "for batch_idx in tqdm(range(n_batches), desc=\"Baseline batches\"):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, n_samples)\n",
    "    batch_context = context[start_idx:end_idx]\n",
    "    \n",
    "    # Predict for batch\n",
    "    batch_forecast = pipeline.predict(\n",
    "        inputs=batch_context,\n",
    "        prediction_length=prediction_length,\n",
    "    )\n",
    "    \n",
    "    # Extract predictions and compute metrics\n",
    "    for i, forecast in enumerate(batch_forecast):\n",
    "        pred = forecast[0].median(dim=0).values.numpy()\n",
    "        baseline_preds.append(pred)\n",
    "        \n",
    "        y_true = future_values[start_idx + i].numpy()\n",
    "        baseline_mae_per_series.append(compute_mae(y_true, pred))\n",
    "        baseline_rmse_per_series.append(compute_rmse(y_true, pred))\n",
    "        baseline_mase_per_series.append(compute_mase(y_true, pred))\n",
    "\n",
    "baseline_mae_per_series = np.array(baseline_mae_per_series)\n",
    "baseline_rmse_per_series = np.array(baseline_rmse_per_series)\n",
    "baseline_mase_per_series = np.array(baseline_mase_per_series)\n",
    "\n",
    "print(\"✓ Baseline prediction completed\\n\")\n",
    "\n",
    "# Display final baseline results\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE RESULTS (Hard Group Masking)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average MAE:  {baseline_mae_per_series.mean():.4f} (±{baseline_mae_per_series.std():.4f})\")\n",
    "print(f\"Average RMSE: {baseline_rmse_per_series.mean():.4f} (±{baseline_rmse_per_series.std():.4f})\")\n",
    "print(f\"Average MASE: {baseline_mase_per_series.mean():.4f} (±{baseline_mase_per_series.std():.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Run soft masking prediction + compute metrics\n",
    "print(\"Running soft masking prediction (correlation-based)...\")\n",
    "\n",
    "# Process in batches with progress bar\n",
    "batch_size = 256\n",
    "n_samples = len(context)\n",
    "n_batches = (n_samples + batch_size - 1) // batch_size\n",
    "\n",
    "soft_preds = []\n",
    "soft_mae_per_series = []\n",
    "soft_rmse_per_series = []\n",
    "soft_mase_per_series = []\n",
    "\n",
    "for batch_idx in tqdm(range(n_batches), desc=\"Soft masking batches\"):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, n_samples)\n",
    "    batch_context = context[start_idx:end_idx]\n",
    "    \n",
    "    # Predict for batch with soft masking\n",
    "    batch_forecast = pipeline.predict(\n",
    "        inputs=batch_context,\n",
    "        prediction_length=prediction_length,\n",
    "        use_soft_group_mask=True,\n",
    "        similarity_type=\"correlation\",\n",
    "        soft_mask_temperature=5.0,\n",
    "    )\n",
    "    \n",
    "    # Extract predictions and compute metrics\n",
    "    for i, forecast in enumerate(batch_forecast):\n",
    "        pred = forecast[0].median(dim=0).values.numpy()\n",
    "        soft_preds.append(pred)\n",
    "        \n",
    "        y_true = future_values[start_idx + i].numpy()\n",
    "        soft_mae_per_series.append(compute_mae(y_true, pred))\n",
    "        soft_rmse_per_series.append(compute_rmse(y_true, pred))\n",
    "        soft_mase_per_series.append(compute_mase(y_true, pred))\n",
    "\n",
    "soft_mae_per_series = np.array(soft_mae_per_series)\n",
    "soft_rmse_per_series = np.array(soft_rmse_per_series)\n",
    "soft_mase_per_series = np.array(soft_mase_per_series)\n",
    "\n",
    "print(\"✓ Soft masking prediction completed\\n\")\n",
    "\n",
    "# Display final soft masking results\n",
    "print(\"=\"*60)\n",
    "print(\"SOFT MASKING RESULTS (Correlation-based)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average MAE:  {soft_mae_per_series.mean():.4f} (±{soft_mae_per_series.std():.4f})\")\n",
    "print(f\"Average RMSE: {soft_rmse_per_series.mean():.4f} (±{soft_rmse_per_series.std():.4f})\")\n",
    "print(f\"Average MASE: {soft_mase_per_series.mean():.4f} (±{soft_mase_per_series.std():.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Statistical comparison between baseline and soft masking\n",
    "\n",
    "# Display final baseline results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL BASELINE RESULTS (Hard Group Masking)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average MAE:  {baseline_mae_per_series.mean():.4f} (±{baseline_mae_per_series.std():.4f})\")\n",
    "print(f\"Average RMSE: {baseline_rmse_per_series.mean():.4f} (±{baseline_rmse_per_series.std():.4f})\")\n",
    "print(f\"Average MASE: {baseline_mase_per_series.mean():.4f} (±{baseline_mase_per_series.std():.4f})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "# Display final soft masking results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SOFT MASKING RESULTS (Correlation-based)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average MAE:  {soft_mae_per_series.mean():.4f} (±{soft_mae_per_series.std():.4f})\")\n",
    "print(f\"Average RMSE: {soft_rmse_per_series.mean():.4f} (±{soft_rmse_per_series.std():.4f})\")\n",
    "print(f\"Average MASE: {soft_mase_per_series.mean():.4f} (±{soft_mase_per_series.std():.4f})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: BASELINE vs SOFT MASKING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate improvement percentage\n",
    "mae_improvement = ((baseline_mae_per_series.mean() - soft_mae_per_series.mean()) / baseline_mae_per_series.mean()) * 100\n",
    "rmse_improvement = ((baseline_rmse_per_series.mean() - soft_rmse_per_series.mean()) / baseline_rmse_per_series.mean()) * 100\n",
    "mase_improvement = ((baseline_mase_per_series.mean() - soft_mase_per_series.mean()) / baseline_mase_per_series.mean()) * 100\n",
    "\n",
    "print(f\"MAE Improvement:  {mae_improvement:+.2f}%\")\n",
    "print(f\"RMSE Improvement: {rmse_improvement:+.2f}%\")\n",
    "print(f\"MASE Improvement: {mase_improvement:+.2f}%\")\n",
    "\n",
    "# Paired t-test for statistical significance\n",
    "mae_t_stat, mae_p_value = ttest_rel(baseline_mae_per_series, soft_mae_per_series)\n",
    "rmse_t_stat, rmse_p_value = ttest_rel(baseline_rmse_per_series, soft_rmse_per_series)\n",
    "mase_t_stat, mase_p_value = ttest_rel(baseline_mase_per_series, soft_mase_per_series)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SIGNIFICANCE (Paired t-test)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE:  t={mae_t_stat:.4f}, p={mae_p_value:.6f}\")\n",
    "print(f\"RMSE: t={rmse_t_stat:.4f}, p={rmse_p_value:.6f}\")\n",
    "print(f\"MASE: t={mase_t_stat:.4f}, p={mase_p_value:.6f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if mae_p_value < alpha:\n",
    "    print(f\"\\n✓ MAE difference is statistically significant (p < {alpha})\")\n",
    "else:\n",
    "    print(f\"\\n✗ MAE difference is NOT statistically significant (p >= {alpha})\")\n",
    "\n",
    "if rmse_p_value < alpha:\n",
    "    print(f\"✓ RMSE difference is statistically significant (p < {alpha})\")\n",
    "else:\n",
    "    print(f\"✗ RMSE difference is NOT statistically significant (p >= {alpha})\")\n",
    "\n",
    "if mase_p_value < alpha:\n",
    "    print(f\"✓ MASE difference is statistically significant (p < {alpha})\")\n",
    "else:\n",
    "    print(f\"✗ MASE difference is NOT statistically significant (p >= {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to Cell 7 (comparison section)\n",
    "# Effect size (Cohen's d)\n",
    "pooled_std_mae = np.sqrt((baseline_mae_per_series.std()**2 + soft_mae_per_series.std()**2) / 2)\n",
    "cohens_d_mae = (baseline_mae_per_series.mean() - soft_mae_per_series.mean()) / pooled_std_mae\n",
    "\n",
    "print(f\"\\nEffect Size (Cohen's d)\")\n",
    "print(f\"MAE: {cohens_d_mae:.4f}\")\n",
    "print(\"Interpretation: <0.2=negligible, 0.2-0.5=small, 0.5-0.8=medium, >0.8=large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# MAE comparison\n",
    "axes[0, 0].hist(baseline_mae_per_series, bins=20, alpha=0.7, label='Baseline', color='blue')\n",
    "axes[0, 0].hist(soft_mae_per_series, bins=20, alpha=0.7, label='Soft Masking', color='orange')\n",
    "axes[0, 0].set_xlabel('MAE')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('MAE Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0, 1].hist(baseline_rmse_per_series, bins=20, alpha=0.7, label='Baseline', color='blue')\n",
    "axes[0, 1].hist(soft_rmse_per_series, bins=20, alpha=0.7, label='Soft Masking', color='orange')\n",
    "axes[0, 1].set_xlabel('RMSE')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('RMSE Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# MASE comparison\n",
    "axes[0, 2].hist(baseline_mase_per_series, bins=20, alpha=0.7, label='Baseline', color='blue')\n",
    "axes[0, 2].hist(soft_mase_per_series, bins=20, alpha=0.7, label='Soft Masking', color='orange')\n",
    "axes[0, 2].set_xlabel('MASE')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].set_title('MASE Distribution')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Per-series MAE comparison\n",
    "axes[1, 0].scatter(baseline_mae_per_series, soft_mae_per_series, alpha=0.6)\n",
    "axes[1, 0].plot([baseline_mae_per_series.min(), baseline_mae_per_series.max()],\n",
    "                [baseline_mae_per_series.min(), baseline_mae_per_series.max()],\n",
    "                'r--', linewidth=2, label='y=x')\n",
    "axes[1, 0].set_xlabel('Baseline MAE')\n",
    "axes[1, 0].set_ylabel('Soft Masking MAE')\n",
    "axes[1, 0].set_title('Per-Series MAE Comparison')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Per-series RMSE comparison\n",
    "axes[1, 1].scatter(baseline_rmse_per_series, soft_rmse_per_series, alpha=0.6)\n",
    "axes[1, 1].plot([baseline_rmse_per_series.min(), baseline_rmse_per_series.max()],\n",
    "                [baseline_rmse_per_series.min(), baseline_rmse_per_series.max()],\n",
    "                'r--', linewidth=2, label='y=x')\n",
    "axes[1, 1].set_xlabel('Baseline RMSE')\n",
    "axes[1, 1].set_ylabel('Soft Masking RMSE')\n",
    "axes[1, 1].set_title('Per-Series RMSE Comparison')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Per-series MASE comparison\n",
    "axes[1, 2].scatter(baseline_mase_per_series, soft_mase_per_series, alpha=0.6)\n",
    "axes[1, 2].plot([baseline_mase_per_series.min(), baseline_mase_per_series.max()],\n",
    "                [baseline_mase_per_series.min(), baseline_mase_per_series.max()],\n",
    "                'r--', linewidth=2, label='y=x')\n",
    "axes[1, 2].set_xlabel('Baseline MASE')\n",
    "axes[1, 2].set_ylabel('Soft Masking MASE')\n",
    "axes[1, 2].set_title('Per-Series MASE Comparison')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
